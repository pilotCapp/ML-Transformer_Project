{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 23:39:28.188386: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-08 23:39:28.188803: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-08 23:39:28.191023: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-08 23:39:28.197154: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1731105568.208164 1431109 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1731105568.211218 1431109 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-08 23:39:28.222320: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "Intra-op parallelism threads: 0\n",
      "Inter-op parallelism threads: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 23:39:29.377798: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "\n",
    "print(os.cpu_count())\n",
    "\n",
    "# Optional: Allow TensorFlow to dynamically adjust the number of threads\n",
    "#tf.config.threading.set_intra_op_parallelism_threads(32)\n",
    "#tf.config.threading.set_inter_op_parallelism_threads()\n",
    "\n",
    "print(\"Intra-op parallelism threads:\", tf.config.threading.get_intra_op_parallelism_threads())\n",
    "print(\"Inter-op parallelism threads:\", tf.config.threading.get_inter_op_parallelism_threads())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sequence_length = 10 # Length of the sequence to be fed into the model\n",
    "num_targets = 4  # Number of targets in your data\n",
    "max_future_target = 400  # The maximum future timestep to predict\n",
    "train_instances_per_vessel=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../Datasets/ais_train.csv\", delimiter=\"|\")\n",
    "test_data = pd.read_csv(\"../Datasets/ais_test.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vessel_data = pd.read_csv(\"../Datasets/vessels.csv\", delimiter=\"|\")\n",
    "port_data = pd.read_csv(\"../Datasets/ports.csv\", delimiter=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LabelEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.LabelEncoder.html\">?<span>Documentation for LabelEncoder</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LabelEncoder()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define the categorical and numerical columns\n",
    "categorical_columns = [\"vesselId\", \"shippingLineId\"]\n",
    "numerical_columns = [\"CEU\", \"DWT\", \"GT\", \"breadth\", \"draft\", \"length\"]\n",
    "\n",
    "# Fill NaN values with the mean for numerical columns\n",
    "vessel_data[numerical_columns] = vessel_data[numerical_columns].fillna(vessel_data[numerical_columns].mean())\n",
    "\n",
    "# Scale only the numerical columns\n",
    "vessel_normalizer = MinMaxScaler()\n",
    "vessel_data[numerical_columns] = vessel_normalizer.fit_transform(vessel_data[numerical_columns])\n",
    "\n",
    "# Initialize encoders\n",
    "vessel_encoder = LabelEncoder()\n",
    "shipping_encoder = LabelEncoder()\n",
    "\n",
    "vessel_encoder.fit(vessel_data[\"vesselId\"])\n",
    "shipping_encoder.fit(vessel_data[\"shippingLineId\"])\n",
    "\n",
    "\n",
    "# Now `vessel_data` contains scaled numerical values and unchanged categorical IDs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data[\"time\"] = pd.to_datetime(train_data[\"time\"])\n",
    "test_data[\"time\"] = pd.to_datetime(test_data[\"time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = train_data.merge(\n",
    "    vessel_data[[\"vesselId\", \"shippingLineId\"]], on=\"vesselId\", how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "port_data_renamed = pd.DataFrame()\n",
    "port_data_renamed[[\"portId\", \"port_latitude\", \"port_longitude\"]] = port_data[\n",
    "    [\"portId\", \"latitude\", \"longitude\"]\n",
    "]\n",
    "train_data = train_data.merge(port_data_renamed, on=\"portId\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['time', 'cog', 'sog', 'rot', 'heading', 'navstat', 'etaRaw', 'latitude',\n",
      "       'longitude', 'vesselId', 'portId', 'shippingLineId', 'port_latitude',\n",
      "       'port_longitude'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_navstat(navstat_original):\n",
    "    \"\"\"\n",
    "    Groups the original 16 navstat codes into 5 categories.\n",
    "    \n",
    "    Args:\n",
    "        navstat_original (np.ndarray): Original navstat codes, shape (num_samples, sequence_length)\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Grouped navstat codes, shape (num_samples, sequence_length)\n",
    "    \"\"\"\n",
    "    # Define mapping from original codes to grouped categories\n",
    "    mapping = {\n",
    "        0: 0,  # Underway\n",
    "        1: 1,  # Stationary\n",
    "        2: 1,  # Stationary\n",
    "        3: 1,  # Stationary\n",
    "        4: 1,  # Stationary\n",
    "        5: 1,  # Stationary\n",
    "        6: 1,  # Stationary\n",
    "        7: 2,  # Fishing\n",
    "        8: 0,  # Underway\n",
    "        9: 3,  # Other\n",
    "        10: 3, # Other\n",
    "        11: 3, # Other\n",
    "        12: 3, # Other\n",
    "        13: 3, # Other\n",
    "        14: 4, # Emergency\n",
    "        15: 4  # Emergency\n",
    "    }\n",
    "    \n",
    "    # Vectorized mapping\n",
    "    vectorized_mapping = np.vectorize(mapping.get)\n",
    "    navstat_grouped = vectorized_mapping(navstat_original)\n",
    "    \n",
    "    return navstat_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 time    cog   sog  rot  heading  navstat       etaRaw  \\\n",
      "0 2024-01-01 00:00:25  284.0   0.7  0.0     88.0        0  01-09 23:00   \n",
      "1 2024-01-01 00:00:36  109.6   0.0 -6.0    347.0        1  12-29 20:00   \n",
      "2 2024-01-01 00:01:45  111.0  11.0  0.0    112.0        0  01-02 09:00   \n",
      "3 2024-01-01 00:03:11   96.4   0.0  0.0    142.0        1  12-31 20:00   \n",
      "4 2024-01-01 00:03:51  214.0  19.7  0.0    215.0        0  01-25 12:00   \n",
      "\n",
      "   latitude  longitude                  vesselId                    portId  \\\n",
      "0 -34.74370  -57.85130  61e9f3a8b937134a3c4bfdf7  61d371c43aeaecc07011a37f   \n",
      "1   8.89440  -79.47939  61e9f3d4b937134a3c4bff1f  634c4de270937fc01c3a7689   \n",
      "2  39.19065  -76.47567  61e9f436b937134a3c4c0131  61d3847bb7b7526e1adf3d19   \n",
      "3 -34.41189  151.02067  61e9f3b4b937134a3c4bfe77  61d36f770a1807568ff9a126   \n",
      "4  35.88379   -5.91636  61e9f41bb937134a3c4c0087  634c4de270937fc01c3a74f3   \n",
      "\n",
      "             shippingLineId  port_latitude  port_longitude  \n",
      "0  61ec65aea8cafc0e93f0e900       -33.5875      -71.618889  \n",
      "1  61be24564ea00ae59d0fe37a         8.9670      -79.533000  \n",
      "2  61be24564ea00ae59d0fe379        39.2325      -76.558889  \n",
      "3  61a8e672f9cba188601e84ac       -34.4625      150.899444  \n",
      "4  61be24564ea00ae59d0fe37a        35.7830       -5.817000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1431109/3926903193.py:25: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda group: group.ffill().bfill())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 time    cog   sog  rot  heading  navstat       etaRaw  \\\n",
      "0 2024-01-12 14:07:47  308.1  17.1 -6.0    316.0        0  01-08 06:00   \n",
      "1 2024-01-12 14:31:00  307.6  17.3  5.0    313.0        0  01-14 23:30   \n",
      "2 2024-01-12 14:57:23  306.8  16.9  5.0    312.0        0  01-14 23:30   \n",
      "3 2024-01-12 15:18:48  307.9  16.9  6.0    313.0        0  01-14 23:30   \n",
      "4 2024-01-12 15:39:47  307.0  16.3  7.0    313.0        0  01-14 23:30   \n",
      "\n",
      "   latitude  longitude                  vesselId                    portId  \\\n",
      "0   7.50361   77.58340  61e9f38eb937134a3c4bfd8b  61d376b393c6feb83e5eb50c   \n",
      "1   7.57302   77.49505  61e9f38eb937134a3c4bfd8b  61d376d893c6feb83e5eb546   \n",
      "2   7.65043   77.39404  61e9f38eb937134a3c4bfd8b  61d376d893c6feb83e5eb546   \n",
      "3   7.71275   77.31394  61e9f38eb937134a3c4bfd8b  61d376d893c6feb83e5eb546   \n",
      "4   7.77191   77.23585  61e9f38eb937134a3c4bfd8b  61d376d893c6feb83e5eb546   \n",
      "\n",
      "             shippingLineId  port_latitude  port_longitude  \n",
      "0  61a8e672f9cba188601e84ab      13.263333       80.341111  \n",
      "1  61a8e672f9cba188601e84ab      18.941944       72.885278  \n",
      "2  61a8e672f9cba188601e84ab      18.941944       72.885278  \n",
      "3  61a8e672f9cba188601e84ab      18.941944       72.885278  \n",
      "4  61a8e672f9cba188601e84ab      18.941944       72.885278  \n"
     ]
    }
   ],
   "source": [
    "train_data_preprocessed = train_data\n",
    "\n",
    "train_data_preprocessed.loc[train_data_preprocessed[\"cog\"] >= 360, \"cog\"] = np.nan\n",
    "train_data_preprocessed.loc[train_data_preprocessed[\"sog\"] >= 1023, \"sog\"] = np.nan\n",
    "train_data_preprocessed.loc[train_data_preprocessed[\"rot\"] == -128, \"rot\"] = np.nan\n",
    "train_data_preprocessed.loc[train_data_preprocessed[\"heading\"] == 511, \"heading\"] = (\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "pattern = r\"^\\d{2}-\\d{2} \\d{2}:\\d{2}$\"\n",
    "train_data_preprocessed[\"etaRaw\"] = train_data_preprocessed[\"etaRaw\"].where(\n",
    "    train_data_preprocessed[\"etaRaw\"].str.match(pattern, na=False), np.nan\n",
    ")\n",
    "\n",
    "\n",
    "train_data_preprocessed = train_data_preprocessed.sort_values(\"time\")\n",
    "\n",
    "print(train_data_preprocessed.head())\n",
    "\n",
    "\n",
    "train_data_preprocessed = (\n",
    "    train_data_preprocessed.groupby(\"vesselId\")\n",
    "    .apply(lambda group: group.ffill().bfill())\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "\n",
    "print(train_data_preprocessed.head())\n",
    "\n",
    "train_data_preprocessed[\"heading\"] = train_data_preprocessed[\"heading\"].fillna(0)\n",
    "\n",
    "train_data_preprocessed = train_data_preprocessed.dropna().reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Replace '00-' in etaRaw with the corresponding month and day from the 'time' column\n",
    "train_data_preprocessed[\"etaRaw\"] = train_data_preprocessed[\"etaRaw\"].mask(\n",
    "    train_data_preprocessed[\"etaRaw\"].str.contains(\"00-\", na=False),\n",
    "    \"01\" + train_data_preprocessed[\"etaRaw\"].str[2:],\n",
    ")\n",
    "\n",
    "train_data_preprocessed[\"etaRaw\"] = train_data_preprocessed[\"etaRaw\"].mask(\n",
    "    train_data_preprocessed[\"etaRaw\"].str.contains(\"-00\", na=False),\n",
    "    train_data_preprocessed[\"etaRaw\"].str[:2]\n",
    "    + \"-01\"\n",
    "    + train_data_preprocessed[\"etaRaw\"].str[5:],\n",
    ")\n",
    "\n",
    "train_data_preprocessed[\"etaRaw\"] = train_data_preprocessed[\"etaRaw\"].mask(\n",
    "    train_data_preprocessed[\"etaRaw\"].str.contains(\":60\", na=False),\n",
    "    train_data_preprocessed[\"etaRaw\"].str[:9] + \"59\",\n",
    ")\n",
    "\n",
    "train_data_preprocessed[\"etaRaw\"] = train_data_preprocessed[\"etaRaw\"].mask(\n",
    "    train_data_preprocessed[\"etaRaw\"].str.contains(\"60:\", na=False),\n",
    "    train_data_preprocessed[\"etaRaw\"].str[:6] + \"01:00\",\n",
    ")\n",
    "\n",
    "train_data_preprocessed[\"etaRaw\"] = train_data_preprocessed[\"etaRaw\"].mask(\n",
    "    train_data_preprocessed[\"etaRaw\"].str.contains(\"24:\", na=False),\n",
    "    train_data_preprocessed[\"etaRaw\"].str[:6] + \"23:59\",\n",
    ")\n",
    "\n",
    "\n",
    "train_data_preprocessed[\"etaRaw\"] = pd.to_datetime(\n",
    "    train_data_preprocessed[\"time\"].dt.year.astype(str)\n",
    "    + \"-\"\n",
    "    + train_data_preprocessed[\"etaRaw\"]\n",
    "    + \":00\",\n",
    "    format=\"%Y-%m-%d %H:%M:%S\",\n",
    ")\n",
    "\n",
    "\n",
    "train_data_preprocessed[\"seconds_to_eta\"] = (\n",
    "    train_data_preprocessed[\"etaRaw\"] - train_data_preprocessed[\"time\"]\n",
    ").dt.total_seconds()\n",
    "\n",
    "train_data_preprocessed = train_data_preprocessed.drop(columns=[\"etaRaw\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['time', 'vesselId', 'shippingLineId', 'seconds_to_eta', 'latitude_sin',\n",
      "       'latitude_cos', 'longitude_sin', 'longitude_cos', 'port_latitude_sin',\n",
      "       'port_latitude_cos', 'port_longitude_sin', 'port_longitude_cos',\n",
      "       'cog_sog_sin', 'cog_sog_cos'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "train_data_engineered = train_data_preprocessed\n",
    "train_latitude_radians = np.deg2rad(train_data_engineered[\"latitude\"])\n",
    "train_longitude_radians = np.deg2rad(train_data_engineered[\"longitude\"])\n",
    "train_cog_radians = np.deg2rad(train_data_engineered[\"cog\"])\n",
    "train_heading_radians = np.deg2rad(train_data_engineered[\"heading\"])\n",
    "\n",
    "port_latitude_radians = np.deg2rad(train_data_engineered[\"port_latitude\"])\n",
    "port_longitude_radians = np.deg2rad(train_data_engineered[\"port_longitude\"])\n",
    "\n",
    "train_hour = np.deg2rad(train_data_engineered[\"time\"].dt.hour * 360 / 24)\n",
    "train_day = np.deg2rad(train_data_engineered[\"time\"].dt.day * 360 / 30)\n",
    "train_month = np.deg2rad(train_data_engineered[\"time\"].dt.month * 360 / 12)\n",
    "\n",
    "\n",
    "train_latitude_sin = np.sin(train_latitude_radians)\n",
    "train_latitude_cos = np.cos(train_latitude_radians)\n",
    "train_longitude_sin = np.sin(train_longitude_radians)\n",
    "train_longitude_cos = np.cos(train_longitude_radians)\n",
    "\n",
    "port_latitude_sin = np.sin(port_latitude_radians)\n",
    "port_latitude_cos = np.cos(port_latitude_radians)\n",
    "port_longitude_sin = np.sin(port_longitude_radians)\n",
    "port_longitude_cos = np.cos(port_longitude_radians)\n",
    "\n",
    "train_cog_sin = np.sin(train_cog_radians)\n",
    "train_cog_cos = np.cos(train_cog_radians)\n",
    "\n",
    "train_heading_sin = np.sin(train_heading_radians)\n",
    "train_heading_cos = np.cos(train_heading_radians)\n",
    "\n",
    "train_hour_sin = np.sin(train_hour)\n",
    "train_hour_cos = np.cos(train_hour)\n",
    "\n",
    "train_day_sin = np.sin(train_day)\n",
    "train_day_cos = np.cos(train_day)\n",
    "\n",
    "train_month_sin = np.sin(train_month)\n",
    "train_month_cos = np.cos(train_month)\n",
    "\n",
    "\n",
    "train_data_engineered[\"latitude_sin\"] = train_latitude_sin\n",
    "train_data_engineered[\"latitude_cos\"] = train_latitude_cos\n",
    "train_data_engineered[\"longitude_sin\"] = train_longitude_sin\n",
    "train_data_engineered[\"longitude_cos\"] = train_longitude_cos\n",
    "train_data_engineered[\"port_latitude_sin\"] = port_latitude_sin\n",
    "train_data_engineered[\"port_latitude_cos\"] = port_latitude_cos\n",
    "train_data_engineered[\"port_longitude_sin\"] = port_longitude_sin\n",
    "train_data_engineered[\"port_longitude_cos\"] = port_longitude_cos\n",
    "train_data_engineered[\"cog_sin\"] = train_cog_sin\n",
    "train_data_engineered[\"cog_cos\"] = train_cog_cos\n",
    "train_data_engineered[\"heading_sin\"] = train_heading_sin\n",
    "train_data_engineered[\"heading_cos\"] = train_heading_cos\n",
    "\n",
    "train_data_engineered[\"hour_sin\"] = train_hour_sin\n",
    "train_data_engineered[\"hour_cos\"] = train_hour_cos\n",
    "train_data_engineered[\"day_sin\"] = train_day_sin\n",
    "train_data_engineered[\"day_cos\"] = train_day_cos\n",
    "train_data_engineered[\"month_sin\"] = train_month_sin\n",
    "train_data_engineered[\"month_cos\"] = train_month_cos\n",
    "\n",
    "\n",
    "train_data_engineered[\"cog_sog_sin\"] = (\n",
    "    train_data_engineered[\"cog_sin\"] * train_data_engineered[\"sog\"]\n",
    ")\n",
    "train_data_engineered[\"cog_sog_cos\"] = (\n",
    "    train_data_engineered[\"cog_cos\"] * train_data_engineered[\"sog\"]\n",
    ")\n",
    "\n",
    "train_data_engineered = train_data_engineered.drop(\n",
    "    columns=[\n",
    "        \"latitude\",\n",
    "        \"longitude\",\n",
    "        \"cog\",\n",
    "        \"heading\",\n",
    "        \"portId\",\n",
    "        \"cog_sin\",\n",
    "        \"cog_cos\",\n",
    "        \"sog\",\n",
    "        #\"shippingLineId\", \n",
    "        \"navstat\",\n",
    "        \"heading_sin\",\n",
    "        \"heading_cos\",\n",
    "        \"port_latitude\",\n",
    "        \"port_longitude\",\n",
    "        #\"port_latitude_sin\",\n",
    "        #\"port_latitude_cos\",\n",
    "        #\"port_longitude_sin\",\n",
    "        #\"port_longitude_cos\",\n",
    "        \"hour_sin\",\n",
    "        \"hour_cos\",\n",
    "        \"day_sin\",\n",
    "        \"day_cos\",\n",
    "        \"month_sin\",\n",
    "        \"month_cos\",\n",
    "        \"rot\", #probably not important, removed because I needed only 18 features\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "print(train_data_engineered.columns)\n",
    "\n",
    "seconds_to_eta_scaler = MinMaxScaler()\n",
    "rot_scaler = MinMaxScaler()\n",
    "cog_sog_sin_scaler = MinMaxScaler()\n",
    "cog_sog_cos_scaler = MinMaxScaler()\n",
    "\n",
    "train_data_engineered[\"seconds_to_eta\"] = seconds_to_eta_scaler.fit_transform(\n",
    "    train_data_engineered[\"seconds_to_eta\"].values.reshape(-1, 1)\n",
    ")\n",
    "train_data_engineered[\"cog_sog_sin\"] = cog_sog_sin_scaler.fit_transform(\n",
    "    train_data_engineered[\"cog_sog_sin\"].values.reshape(-1, 1)\n",
    ")\n",
    "train_data_engineered[\"cog_sog_cos\"] = cog_sog_cos_scaler.fit_transform(\n",
    "    train_data_engineered[\"cog_sog_cos\"].values.reshape(-1, 1)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['time', 'vesselId', 'shippingLineId', 'seconds_to_eta',\n",
      "       'port_latitude_sin', 'port_latitude_cos', 'port_longitude_sin',\n",
      "       'port_longitude_cos', 'cog_sog_sin', 'cog_sog_cos', 'latitude_sin',\n",
      "       'latitude_cos', 'longitude_sin', 'longitude_cos'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Specify the columns you want to move to the end\n",
    "columns_to_move_last = [\"latitude_sin\", \"latitude_cos\" ,\"longitude_sin\",\"longitude_cos\"]\n",
    "\n",
    "# Get a list of all columns\n",
    "all_columns = train_data_engineered.columns.tolist()\n",
    "\n",
    "# Filter out the columns you want to move to the end\n",
    "columns_to_keep = [col for col in all_columns if col not in columns_to_move_last]\n",
    "\n",
    "# Create the new column order: first keep all other columns, then add the specified columns at the end\n",
    "new_column_order = columns_to_keep + columns_to_move_last\n",
    "\n",
    "# Reorder the DataFrame\n",
    "train_data_engineered = train_data_engineered[new_column_order]\n",
    "\n",
    "# Check the column order\n",
    "print(train_data_engineered.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_features=len(train_data_engineered.columns)-3 +1 # remove time vesselId and shippingLaneId, add time_diff\n",
    "print(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_diff_scaler = MinMaxScaler()\n",
    "time_diff_index = 0\n",
    "\n",
    "\n",
    "def create_sequences(\n",
    "    data: pd.DataFrame,\n",
    "    sequence_length: int,\n",
    "    train_instances_per_vessel: int,\n",
    "    min_sequence_length: int = 10,\n",
    "    max_future_target=400,\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates sequences of a specified length from the input data for each vessel.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): The input data containing 'vesselId', 'time', and feature columns.\n",
    "        sequence_length (int): The desired length of each sequence.\n",
    "        max_future_target (int): The maximum number of steps ahead to predict.\n",
    "        train_instances_per_vessel (int): The number of training instances to generate per vessel.\n",
    "        min_sequence_length (int): The minimum number of data points required to create a sequence.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, int]:\n",
    "            A tuple containing the input sequences (X), targets (y), vessel IDs, times, and time_diff_index.\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    vessel_ids = []\n",
    "    shipping_ids=[]\n",
    "    times = []\n",
    "    all_time_diffs = []\n",
    "\n",
    "    \n",
    "\n",
    "    # Combine non_sequential_feature_columns with other columns to exclude them from sequential_feature_columns\n",
    "    sequential_feature_columns = [\n",
    "        col for col in data.columns if col not in [\"vesselId\",\"time\", \"shippingLineId\"]\n",
    "    ]\n",
    "\n",
    "    sequential_feature_columns.append(\"time_diff\")\n",
    "\n",
    "    print(\"Feature Columns:\", sequential_feature_columns)\n",
    "\n",
    "    # Group data by 'vesselId'\n",
    "    grouped = data.groupby(\"vesselId\")\n",
    "\n",
    "    future_target=1\n",
    "\n",
    "    while future_target<=max_future_target:\n",
    "\n",
    "        for vessel_id, group in grouped:\n",
    "            # Sort the group by 'time'\n",
    "            group = group.sort_values(\"time\").reset_index(drop=True)\n",
    "            shipping_id=group[\"shippingLineId\"][0]\n",
    "    \n",
    "            # Skip vessels with insufficient data\n",
    "            if len(group) < min_sequence_length:\n",
    "                continue\n",
    "    \n",
    "            # Calculate time differences to the next instance\n",
    "            group[\"time_diff\"] = (\n",
    "                (group[\"time\"].diff(-1).dt.total_seconds()/10**6).abs().fillna(0)\n",
    "            )\n",
    "            \n",
    "    \n",
    "            # Convert features to numpy array\n",
    "            feature_array = group[sequential_feature_columns].values\n",
    "    \n",
    "            # Pad sequences if necessary\n",
    "            if len(feature_array) < sequence_length + future_target:\n",
    "                padding_length = sequence_length + future_target - len(feature_array)\n",
    "                padding = np.zeros((padding_length, feature_array.shape[1]))\n",
    "                feature_array = np.vstack([feature_array, padding])\n",
    "    \n",
    "            # Update the group length after padding\n",
    "            group_length = len(feature_array)\n",
    "    \n",
    "            num_possible_sequences = group_length - sequence_length - int(future_target/2) + 1\n",
    "    \n",
    "            # Determine the actual number of sequences we can generate\n",
    "            actual_instances = min(train_instances_per_vessel, num_possible_sequences)\n",
    "            if actual_instances <= 0:\n",
    "                continue\n",
    "    \n",
    "            # Calculate step size\n",
    "            if actual_instances == 1:\n",
    "                step_size = 0  # Only one sequence possible\n",
    "            else:\n",
    "                step_size = num_possible_sequences / (actual_instances) - 1\n",
    "    \n",
    "            for i in range(actual_instances):\n",
    "                k = int(i * step_size)\n",
    "                seq_x = feature_array[k : k + sequence_length].copy()\n",
    "    \n",
    "                # Randomly select future target N steps ahead (1 to future_target inclusive)\n",
    "                N = future_target\n",
    "                \n",
    "                target_idx = k + sequence_length + N  # Adjust index accordingly\n",
    "    \n",
    "                # Handle the case where target_idx is beyond the length of the data\n",
    "                if target_idx >= group_length:\n",
    "                    # setting last known position as target (in order to use more of the data for longer future targets)\n",
    "                    target_idx = group_length-1\n",
    "    \n",
    "                # Get seq_y\n",
    "                seq_y = feature_array[target_idx,-5:-1]  # Assuming target variables are included\n",
    "    \n",
    "                last_seq_time = group[\"time\"].iloc[min(k + sequence_length - 1, len(group)-1)]\n",
    "                target_time = group[\"time\"].iloc[min(target_idx, len(group)-1)]\n",
    "                time_diff_cumulative = (target_time - last_seq_time).total_seconds()/10**6\n",
    "    \n",
    "                # Update the last time_diff in seq_x to be time_diff_cumulative\n",
    "                seq_x[-1, -1] = time_diff_cumulative\n",
    "    \n",
    "                all_time_diffs.extend(seq_x[:, -1])\n",
    "    \n",
    "                # Append sequences and targets\n",
    "                sequences.append(seq_x)\n",
    "                targets.append(seq_y)\n",
    "                vessel_ids.append(vessel_id)\n",
    "                shipping_ids.append(shipping_id)\n",
    "                times.append(last_seq_time)\n",
    "\n",
    "        previus_future_target = future_target\n",
    "        future_target = int(future_target**(1.05))\n",
    "        if future_target == previus_future_target:\n",
    "            future_target += 1\n",
    "        print(future_target)\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    X = np.array(sequences).astype(np.float32)\n",
    "    y = np.array(targets).astype(np.float32)\n",
    "    vessel_ids = np.array(vessel_ids)\n",
    "    shipping_ids=np.array(shipping_ids)\n",
    "    times = np.array(times)\n",
    "    \n",
    "    return X, y, vessel_ids, shipping_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['time', 'vesselId', 'shippingLineId', 'seconds_to_eta',\n",
      "       'port_latitude_sin', 'port_latitude_cos', 'port_longitude_sin',\n",
      "       'port_longitude_cos', 'cog_sog_sin', 'cog_sog_cos', 'latitude_sin',\n",
      "       'latitude_cos', 'longitude_sin', 'longitude_cos'],\n",
      "      dtype='object')\n",
      "Creating sequenced data\n",
      "Feature Columns: ['seconds_to_eta', 'port_latitude_sin', 'port_latitude_cos', 'port_longitude_sin', 'port_longitude_cos', 'cog_sog_sin', 'cog_sog_cos', 'latitude_sin', 'latitude_cos', 'longitude_sin', 'longitude_cos', 'time_diff']\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "17\n",
      "19\n",
      "22\n",
      "25\n",
      "29\n",
      "34\n",
      "40\n",
      "48\n",
      "58\n",
      "71\n",
      "87\n",
      "108\n",
      "136\n",
      "173\n",
      "223\n",
      "292\n",
      "387\n",
      "521\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(train_data_engineered.columns)\n",
    "train_data_sequenced_X = []\n",
    "train_data_sequenced_Y = []\n",
    "\n",
    "if os.path.exists(\n",
    "    f\"intermediate/train_data_sequenced_X_{sequence_length}_{max_future_target}.npy\"\n",
    "):\n",
    "    print(\"Loading sequenced data from file\")\n",
    "    train_data_sequenced_X = np.load(\n",
    "        f\"intermediate/train_data_sequenced_X_{sequence_length}_{max_future_target}.npy\",\n",
    "        allow_pickle=True,\n",
    "    )\n",
    "    train_data_sequenced_Y = np.load(\n",
    "        f\"intermediate/train_data_sequenced_Y_{sequence_length}_{max_future_target}.npy\",\n",
    "        allow_pickle=True,\n",
    "    )\n",
    "else:\n",
    "    print(\"Creating sequenced data\")\n",
    "    train_data_sequenced_X, train_data_sequenced_Y, vessel_ids, shipping_ids = create_sequences(\n",
    "        train_data_engineered,\n",
    "        sequence_length=sequence_length,\n",
    "        train_instances_per_vessel=train_instances_per_vessel,\n",
    "    )\n",
    "\n",
    "    # Transform the IDs to integer labels\n",
    "    vessel_ids = vessel_encoder.transform(vessel_ids)\n",
    "    shipping_ids = shipping_encoder.transform(shipping_ids)\n",
    "    \n",
    "    #np.save(f\"intermediate/train_data_sequenced_X_{sequence_length}_{future_target}.npy\",train_data_sequenced_X)\n",
    "    #np.save(f\"intermediate/train_data_sequenced_Y_{sequence_length}_{future_target}.npy\",train_data_sequenced_Y)\n",
    "\n",
    "# train_data_shifted_df = train_data_shifted_df.drop(columns=[\"time\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def append_last_known_data_test(\n",
    "    test_data: pd.DataFrame,\n",
    "    known_data: pd.DataFrame,\n",
    "     vessel_information: pd.DataFrame\n",
    "):\n",
    "    \"\"\"\n",
    "    Groups training data by vesselId and propagates all data from the last known location.\n",
    "    Pads sequences shorter than sequence_length.\n",
    "\n",
    "    Args:\n",
    "        test_data (pd.DataFrame): The test data containing 'vesselId' and 'time'.\n",
    "        known_data (pd.DataFrame): The known data to extract last known positions.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[np.ndarray, pd.Series]: A tuple containing the numpy array of sequences and the original times.\n",
    "    \"\"\"\n",
    "    vessel_information=vessel_information.set_index(\"vesselId\")\n",
    "    \n",
    "    test_data[\"time\"] = pd.to_datetime(test_data[\"time\"])\n",
    "\n",
    "     # Determine the feature columns (excluding 'time' and 'vesselId')\n",
    "    \n",
    "    # Combine non_sequential_feature_columns with other columns to exclude them from sequential_feature_columns\n",
    "    sequential_feature_columns = known_data.columns.values\n",
    "    \n",
    "    \n",
    "    sequential_known_data=known_data[sequential_feature_columns]\n",
    "\n",
    "    # Group known_data by 'vesselId', sort by 'time', and take the last sequence_length records\n",
    "    grouped_data = (\n",
    "        sequential_known_data.sort_values(\"time\")\n",
    "        .groupby(\"vesselId\")\n",
    "        .tail(sequence_length)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    grouped_data[\"time_diff\"] = (\n",
    "        (grouped_data.groupby(\"vesselId\")[\"time\"]\n",
    "        .diff(-1)\n",
    "        .dt.total_seconds()/10**6)\n",
    "        .abs()\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "    test_data_numpy = []\n",
    "    vessel_ids=[]\n",
    "    shipping_ids=[]\n",
    "    all_time_diffs = []\n",
    "\n",
    "\n",
    "    for idx, row in test_data.iterrows():\n",
    "        vessel_id = row[\"vesselId\"]\n",
    "        current_vessel_data=vessel_information.loc[vessel_id]\n",
    "        shipping_id=current_vessel_data[\"shippingLineId\"]        \n",
    "        \n",
    "        test_time = row[\"time\"]\n",
    "\n",
    "        # Extract current data for the current vessel_id\n",
    "        current_data = grouped_data[grouped_data[\"vesselId\"] == vessel_id]\n",
    "        \n",
    "        if current_data.empty:\n",
    "            raise ValueError(f\"vesselId {vessel_id} not found in known_data.\")\n",
    "\n",
    "        # Get the actual sequence length\n",
    "        actual_sequence_length = len(current_data)\n",
    "\n",
    "        # Calculate cumulative time difference and scale it\n",
    "        last_idx = current_data.index[-1]\n",
    "        time_diff_cumulative = (test_time - current_data.loc[last_idx, \"time\"]).total_seconds()/10**6\n",
    "\n",
    "        # Update 'time_diff' in vessel_data\n",
    "        current_data.loc[last_idx, \"time_diff\"] = time_diff_cumulative\n",
    "\n",
    "        # Select wanted sequential features\n",
    "        current_data = current_data.drop([\"time\",\"vesselId\",\"shippingLineId\"],axis=1)\n",
    "\n",
    "        # Handle padding if the sequence is shorter than sequence_length\n",
    "        if actual_sequence_length < sequence_length:\n",
    "            # Calculate how many padding steps are needed\n",
    "            padding_needed = sequence_length - actual_sequence_length\n",
    "\n",
    "            # Create padding array with zeros (or a specified padding value)\n",
    "            padding_array = np.zeros((padding_needed, current_data.shape[1]))\n",
    "\n",
    "            # Optionally, you can set specific values for 'time_diff' in the padding\n",
    "            time_diff_index = current_data.columns.get_loc(\"time_diff\")\n",
    "            padding_array[:, time_diff_index] = 0  # Set 'time_diff' in padding to zero\n",
    "\n",
    "            # Convert vessel_data to numpy array\n",
    "            vessel_array = current_data.values\n",
    "\n",
    "            # Concatenate padding to the beginning of the sequence\n",
    "            vessel_array = np.vstack((padding_array, vessel_array))\n",
    "        else:\n",
    "            # Convert vessel_data to numpy array\n",
    "            vessel_array = current_data.values\n",
    "\n",
    "        # Ensure the final sequence has the correct length\n",
    "        assert vessel_array.shape[0] == sequence_length, f\"Sequence length mismatch for vessel {vessel_id}\"\n",
    "\n",
    "        # Append to the list\n",
    "        test_data_numpy.append(vessel_array)\n",
    "        vessel_ids.append(vessel_id)\n",
    "        shipping_ids.append(shipping_id)\n",
    "        \n",
    "    original_time = test_data[\"time\"]\n",
    "    vessels = test_data[\"vesselId\"]\n",
    "    \n",
    "\n",
    "    return np.array(test_data_numpy).astype(np.float32), np.array(vessel_ids), np.array(shipping_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating test data\n"
     ]
    }
   ],
   "source": [
    "test_data_X=0\n",
    "\n",
    "if os.path.exists(\n",
    "    f\"intermediate/test_data_sequenced_X_{sequence_length}_{max_future_target}.npy\"\n",
    "    ):\n",
    "    print(\"loading test data\")\n",
    "    test_data_X=np.load(f\"intermediate/test_data_sequenced_X_{sequence_length}_{max_future_target}.npy\", allow_pickle=True)\n",
    "else:\n",
    "    print(\"creating test data\")\n",
    "    test_data_X, test_vessel_ids,test_shipping_ids = append_last_known_data_test(test_data, train_data_engineered,vessel_data.copy())\n",
    "    \n",
    "    test_vessel_ids = vessel_encoder.transform(test_vessel_ids)\n",
    "    test_shipping_ids = shipping_encoder.transform(test_shipping_ids)\n",
    "    #np.save(f\"intermediate/test_data_sequenced_X_{sequence_length}_{max_future_target}.npy\", test_data_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.26093897 0.8085266  0.5884597  0.18856698 0.9820603  0.4152345\n",
      " 0.43379942 0.85954654 0.51105744 0.37444007 0.9272511  0.448658  ]\n",
      "[0.263523   0.32460994 0.945848   0.95571744 0.2942859  0.43754008\n",
      " 0.5479032  0.13979493 0.9901805  0.9739797  0.22663516 0.00258   ]\n",
      "(51739, 10, 12)\n"
     ]
    }
   ],
   "source": [
    "print(test_data_X[-2,-1,:])\n",
    "print(train_data_sequenced_X[9,-1,:])\n",
    "print(test_data_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "class ContinuousPositionalEncoding(layers.Layer):\n",
    "    def __init__(self, d_model, **kwargs):\n",
    "        \"\"\"\n",
    "        Initializes the ContinuousPositionalEncoding layer.\n",
    "\n",
    "        Args:\n",
    "            d_model (int): The dimensionality of the model.\n",
    "            **kwargs: Additional keyword arguments for the Layer base class.\n",
    "        \"\"\"\n",
    "        super(ContinuousPositionalEncoding, self).__init__(**kwargs)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, time_differences):\n",
    "        \"\"\"\n",
    "        Computes the positional encoding based on cumulative time differences.\n",
    "\n",
    "        Args:\n",
    "            time_differences (tf.Tensor): A tensor of shape (batch_size, sequence_length)\n",
    "                                          containing cumulative time differences.\n",
    "\n",
    "        Returns:\n",
    "            tf.Tensor: Positional encoding tensor of shape (batch_size, sequence_length, d_model).\n",
    "        \"\"\"\n",
    "        # Compute cumulative time positions\n",
    "        time_positions = tf.cumsum(time_differences, axis=1)*sequence_length # Shape: (batch_size, sequence_length)\n",
    "        position = tf.expand_dims(time_positions, axis=-1)    # Shape: (batch_size, sequence_length, 1)\n",
    "\n",
    "        # Compute the angle rates\n",
    "        i = tf.range(self.d_model, dtype=tf.float32)          # Shape: (d_model,)\n",
    "        i = tf.reshape(i, (1, 1, self.d_model))               # Shape: (1, 1, d_model)\n",
    "        angle_rates = 1 / tf.pow(10000.0, (2 * (i // 2)) / tf.cast(self.d_model, tf.float32))  # Shape: (1, 1, d_model)\n",
    "        angle_rads = position * angle_rates                   # Shape: (batch_size, sequence_length, d_model)\n",
    "\n",
    "        # Apply sin to even indices and cos to odd indices\n",
    "        sines = tf.sin(angle_rads[..., 0::2])                 # Shape: (batch_size, sequence_length, d_model/2)\n",
    "        cosines = tf.cos(angle_rads[..., 1::2])               # Shape: (batch_size, sequence_length, d_model/2)\n",
    "\n",
    "        # Concatenate sines and cosines along the last axis\n",
    "        pos_encoding = tf.concat([sines, cosines], axis=-1)   # Shape: (batch_size, sequence_length, d_model)\n",
    "\n",
    "        return pos_encoding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class LearnedPositionalEncoding(layers.Layer):\n",
    "    def __init__(self, sequence_length, d_model, **kwargs):\n",
    "        super(LearnedPositionalEncoding, self).__init__(**kwargs)\n",
    "        self.pos_embedding = layers.Embedding(input_dim=sequence_length, output_dim=d_model)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        Adds learned positional embeddings to the input tensor.\n",
    "\n",
    "        Args:\n",
    "            inputs (tf.Tensor): Input tensor of shape (batch_size, sequence_length, d_model).\n",
    "\n",
    "        Returns:\n",
    "            tf.Tensor: Tensor with positional embeddings added.\n",
    "        \"\"\"\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        sequence_length = tf.shape(inputs)[1]\n",
    "        positions = tf.range(start=0, limit=sequence_length, delta=1)\n",
    "        pos_embeddings = self.pos_embedding(positions)  # Shape: (sequence_length, d_model)\n",
    "        pos_embeddings = tf.expand_dims(pos_embeddings, axis=0)  # Shape: (1, sequence_length, d_model)\n",
    "        pos_embeddings = tf.tile(pos_embeddings, [batch_size, 1, 1])  # Shape: (batch_size, sequence_length, d_model)\n",
    "        return inputs + pos_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Layer Normalization\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    # Multi-Head Attention\n",
    "    x = layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs  # Residual Connection\n",
    "\n",
    "    # Feed-Forward Network\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = layers.Dense(ff_dim, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Dense(inputs.shape[-1])(x)\n",
    "    return x + res  # Residual Connection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def build_transformer_model(\n",
    "    sequence_length,\n",
    "    num_features,\n",
    "    num_targets,\n",
    "    head_size,\n",
    "    num_heads,\n",
    "    ff_dim,\n",
    "    num_transformer_blocks,\n",
    "    mlp_units,\n",
    "    d_model,\n",
    "    num_vessels,\n",
    "    vessel_embedding_dim,\n",
    "    num_shipping_lines,\n",
    "    shipping_embedding_dim,\n",
    "    dropout=0,\n",
    "    mlp_dropout=0,\n",
    "):\n",
    "    # Define the input layer for sequential features\n",
    "    feature_inputs = keras.Input(shape=(sequence_length, num_features), name='feature_inputs')\n",
    "    \n",
    "    # Apply masking to the input features\n",
    "    masked_inputs = layers.Masking(mask_value=0.0)(feature_inputs)\n",
    "\n",
    "    # Project features to d_model dimensions\n",
    "    x = layers.Dense(d_model)(masked_inputs)  # Shape: (batch_size, sequence_length, d_model)\n",
    "\n",
    "    # Apply learned positional encoding\n",
    "    x = LearnedPositionalEncoding(sequence_length, d_model)(x)\n",
    "    \n",
    "    # Transformer Encoder Blocks\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    # Global Average Pooling for sequence dimension reduction\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "\n",
    "    # Vessel ID Input and Embedding\n",
    "    vessel_id_input = keras.Input(shape=(1,), name='vessel_id_input')\n",
    "    vessel_embedding = layers.Embedding(input_dim=num_vessels, output_dim=vessel_embedding_dim, name='vessel_embedding')(vessel_id_input)\n",
    "    vessel_embedding = layers.Flatten()(vessel_embedding)  # Shape: (batch_size, vessel_embedding_dim)\n",
    "    \n",
    "    # Shipping ID Input and Embedding\n",
    "    shipping_id_input = keras.Input(shape=(1,), name='shipping_id_input')\n",
    "    shipping_embedding = layers.Embedding(input_dim=num_shipping_lines, output_dim=shipping_embedding_dim, name='shipping_embedding')(shipping_id_input)\n",
    "    shipping_embedding = layers.Flatten()(shipping_embedding)  # Shape: (batch_size, shipping_embedding_dim)\n",
    "\n",
    "    # Concatenate All Paths\n",
    "    concatenated = layers.concatenate([x, vessel_embedding, shipping_embedding], axis=-1)  # Shape: (batch_size, d_model + vessel_embedding_dim + shipping_embedding_dim + 32)\n",
    "\n",
    "    # MLP for Regression\n",
    "    for units in mlp_units:\n",
    "        concatenated = layers.Dense(units, activation=\"relu\")(concatenated)\n",
    "        concatenated = layers.Dropout(mlp_dropout)(concatenated)\n",
    "\n",
    "    # Output layer for regression targets\n",
    "    outputs = layers.Dense(num_targets)(concatenated)\n",
    "    \n",
    "    # Define the model\n",
    "    model = keras.Model(inputs=[feature_inputs, vessel_id_input, shipping_id_input], outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_aggregated_time_diff(data):\n",
    "    aggregated_time_diff=data[:,:,-1]\n",
    "    \n",
    "    # Step 2: Shift time_diff_next by one position to create time_diff_previous\n",
    "    # Set the first entry in each sequence to 0 to represent no previous time difference\n",
    "    aggregated_time_diff = np.roll(aggregated_time_diff, shift=1, axis=1)\n",
    "    aggregated_time_diff[:, 0] = 0  # Set the first entry of each sequence to 0\n",
    "\n",
    "    # Step 3: Calculate the cumulative sum of time_diff_previous along each sequence\n",
    "    aggregated_time_diff = np.cumsum(aggregated_time_diff, axis=1)  # Shape (1471269, sequence_length)\n",
    "    return(aggregated_time_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lhome/kristsey/.local/lib/python3.10/site-packages/keras/src/layers/layer.py:932: UserWarning: Layer 'learned_positional_encoding_1' (of type LearnedPositionalEncoding) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ feature_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ masking_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ feature_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">208</span> │ masking_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ learned_positional… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LearnedPositional…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │ learned_position… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,088</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ learned_position… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,088</span> │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,040</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,088</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,088</span> │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,040</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,088</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,088</span> │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,040</span> │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,088</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │ add_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,088</span> │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,040</span> │ dropout_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ vessel_id_input     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ shipping_id_input   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ add_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ vessel_embedding    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,000</span> │ vessel_id_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ shipping_embedding  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> │ shipping_id_inpu… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ vessel_embedding… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ shipping_embeddi… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,368</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │ dropout_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ feature_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m12\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ masking_1 (\u001b[38;5;33mMasking\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m12\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ feature_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │        \u001b[38;5;34m208\u001b[0m │ masking_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ learned_positional… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │        \u001b[38;5;34m160\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mLearnedPositional…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │         \u001b[38;5;34m32\u001b[0m │ learned_position… │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │      \u001b[38;5;34m1,088\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ learned_position… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │         \u001b[38;5;34m32\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │      \u001b[38;5;34m1,088\u001b[0m │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │      \u001b[38;5;34m1,040\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │         \u001b[38;5;34m32\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │      \u001b[38;5;34m1,088\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │         \u001b[38;5;34m32\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │      \u001b[38;5;34m1,088\u001b[0m │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │      \u001b[38;5;34m1,040\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_3 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │         \u001b[38;5;34m32\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │      \u001b[38;5;34m1,088\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_4 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │         \u001b[38;5;34m32\u001b[0m │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │      \u001b[38;5;34m1,088\u001b[0m │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │      \u001b[38;5;34m1,040\u001b[0m │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_5 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │         \u001b[38;5;34m32\u001b[0m │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │      \u001b[38;5;34m1,088\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_6 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dropout_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │                   │            │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │         \u001b[38;5;34m32\u001b[0m │ add_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │      \u001b[38;5;34m1,088\u001b[0m │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dense_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │      \u001b[38;5;34m1,040\u001b[0m │ dropout_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ vessel_id_input     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ shipping_id_input   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_7 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dense_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ add_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ vessel_embedding    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │     \u001b[38;5;34m12,000\u001b[0m │ vessel_id_input[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ shipping_embedding  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m4\u001b[0m)      │        \u001b[38;5;34m120\u001b[0m │ shipping_id_inpu… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ add_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ vessel_embedding… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ shipping_embeddi… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m2,368\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │        \u001b[38;5;34m260\u001b[0m │ dropout_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">28,236</span> (110.30 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m28,236\u001b[0m (110.30 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">28,236</span> (110.30 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m28,236\u001b[0m (110.30 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d_model=16\n",
    "\n",
    "model = build_transformer_model(\n",
    "    sequence_length=sequence_length,\n",
    "    num_features=num_features,\n",
    "    num_targets=num_targets,  # Define this variable based on your task\n",
    "    head_size=int(d_model/4),\n",
    "    num_heads=4,\n",
    "    ff_dim=d_model*4,\n",
    "    num_transformer_blocks=4,\n",
    "    mlp_units=[d_model*4],\n",
    "    d_model=d_model,\n",
    "    num_vessels=750,\n",
    "    vessel_embedding_dim=16,\n",
    "    num_shipping_lines=30,\n",
    "    shipping_embedding_dim=4,\n",
    "    dropout=0.1,\n",
    "    mlp_dropout=0.1,\n",
    ")\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    loss=\"mean_squared_error\",\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    metrics=[\"mae\"],\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "\n",
    "train_data_sequenced_X=train_data_sequenced_X.astype(np.float32)\n",
    "train_data_sequenced_Y=train_data_sequenced_Y.astype(np.float32)\n",
    "\n",
    "X_train, X_val, y_train, y_val, vessels_train, vessels_val, shipping_ids_train, shipping_ids_val = train_test_split(\n",
    "    train_data_sequenced_X,             # Sequential input features\n",
    "    train_data_sequenced_Y,             # Target output\n",
    "    vessel_ids,                            # Vessel IDs\n",
    "    shipping_ids,                       # Shipping IDs\n",
    "    test_size=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "del train_data_sequenced_X\n",
    "gc.collect() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dataset(sequential_features,vessel_ids, shipping_ids, targets, batch_size):\n",
    "    # Create the dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(((sequential_features,vessel_ids,shipping_ids), targets))\n",
    "    \n",
    "    # Shuffle, batch, and prefetch in one pipeline\n",
    "    dataset = dataset.shuffle(buffer_size=10000) \\\n",
    "                     .batch(batch_size) \\\n",
    "                     .prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "# Create training and validation datasets using the optimized function\n",
    "train_dataset = create_dataset(X_train,vessels_train,shipping_ids_train, y_train, batch_size=1024)\n",
    "val_dataset = create_dataset(X_val,vessels_val,shipping_ids_val, y_val, batch_size=1024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lhome/kristsey/.local/lib/python3.10/site-packages/keras/src/models/functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['feature_inputs', 'vessel_id_input', 'shipping_id_input']. Received: the structure of inputs=('*', '*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m    1/18050\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m49:16:56\u001b[0m 10s/step - loss: 0.9048 - mae: 0.7261"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 23:55:38.669506: E tensorflow/core/util/util.cc:131] oneDNN supports DT_INT32 only on platforms with AVX-512. Falling back to the default Eigen-based implementation if present.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18050/18050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m736s\u001b[0m 40ms/step - loss: 0.0215 - mae: 0.0874 - val_loss: 0.0040 - val_mae: 0.0337\n",
      "Epoch 2/50\n",
      "\u001b[1m18050/18050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m728s\u001b[0m 40ms/step - loss: 0.0083 - mae: 0.0582 - val_loss: 0.0034 - val_mae: 0.0308\n",
      "Epoch 3/50\n",
      "\u001b[1m18050/18050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m748s\u001b[0m 41ms/step - loss: 0.0078 - mae: 0.0564 - val_loss: 0.0032 - val_mae: 0.0301\n",
      "Epoch 4/50\n",
      "\u001b[1m18050/18050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m601s\u001b[0m 33ms/step - loss: 0.0075 - mae: 0.0554 - val_loss: 0.0030 - val_mae: 0.0292\n",
      "Epoch 5/50\n",
      "\u001b[1m13616/18050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2:22\u001b[0m 32ms/step - loss: 0.0073 - mae: 0.0550"
     ]
    }
   ],
   "source": [
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',  # Metric to monitor\n",
    "    patience=5,          # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored metric\n",
    ")\n",
    "\n",
    "# Define the ModelCheckpoint callback\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='training_checkpoint/{epoch:02d}.keras',  # Filepath to save the model\n",
    "    save_freq=25,\n",
    "    save_best_only=False  # Save the model at the specified frequency, not just the best model\n",
    ")\n",
    "\n",
    "# Assuming model, train_dataset, and val_dataset are already defined\n",
    "# Train the model with the EarlyStopping callback\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stopping,checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict future positions\n",
    "prediction_x=[test_data_X,test_vessel_ids,test_shipping_ids]\n",
    "print(test_vessel_ids.dtype)\n",
    "predictions = model.predict(prediction_x)\n",
    "\n",
    "predictions=np.array(predictions).astype(\"float32\")\n",
    "print(predictions.dtype)\n",
    "\n",
    "lat_predictions_radians = np.arctan2(predictions[:,0], predictions[:,1])\n",
    "long_predictions_radians = np.arctan2(predictions[:,2],predictions[:,3])\n",
    "\n",
    "# Convert radians to degrees\n",
    "lat_predictions_degrees = np.rad2deg(lat_predictions_radians)\n",
    "long_predictions_degrees = np.rad2deg(long_predictions_radians)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lat_predictions_degrees)\n",
    "print(long_predictions_degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame({\n",
    "        'ID': range(len(lat_predictions_degrees)),\n",
    "        'longitude_predicted': long_predictions_degrees,\n",
    "        'latitude_predicted': lat_predictions_degrees\n",
    "    })\n",
    "if pd.isna(predictions[\"latitude_predicted\"]).any():\n",
    "    print(\"oh no\")\n",
    "print(predictions.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.to_csv(\"predictions_transformer.csv\", index=False, float_format='%.15f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(predictions))\n",
    "print(len(test_data))\n",
    "print(predictions[\"longitude_predicted\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
